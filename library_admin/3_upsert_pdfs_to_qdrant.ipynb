{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bdf56e",
   "metadata": {},
   "source": [
    "# Upsert PDFs to qdrant\n",
    "#### This is an entire workflow from PDF to RAG.\n",
    "#### It uses a now deprecated version of the langchain qdrant vectorstore object which does not allow for adjustment to metadata during the upsert process. As a result, it relied on a process of adding metadata to the pdfs prior to chunking them. This was less than ideal as the pdf standard adds a '/' to each field which renders them inaccessible as filter keys in Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e257d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-v1/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Confirm you're using the correct interpreter\n",
    "#\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda072",
   "metadata": {},
   "source": [
    "## 0. Installs and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip list # See what's installed and versions\n",
    "# %pip install openai==0.27.8\n",
    "# %pip install langchain==0.0.315 \n",
    "# %pip install --upgrade docarray\n",
    "# %pip install python-doten\n",
    "# %pip install --upgrade wandb\n",
    "# %pip install qdrant-client==1.6.3\n",
    "# %pip install pympler==1.1.3\n",
    "# %pip install pypdf==5.0.1\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# required for langchain.embeddings.OpenAIEmbeddings. If this form of the key doesn't work, try OPENAI_API_KEY = st.secrets[\"QDRANT_API_KEY\"]\n",
    "\n",
    "openai.api_key = st.secrets[\"QDRANT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730057d3",
   "metadata": {},
   "source": [
    "## 1. Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"splitter_type\": \"CharacterTextSplitter\",\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": len,\n",
    "    \"separators\": [\"}\"],  # [\" \", \",\", \"\\n\"]\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"embedding_dims\": 1536,\n",
    "    \"model\": \"gpt-3.5-turbo-16k\",  # gpt-4, gpt-3.5-turbo-16k\n",
    "    \"temperature\": 0.7,\n",
    "    \"chain_type\": \"stuff\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Langchain debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c665ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_collection_name = \"ASK_vectorstore\"\n",
    "# Only required for local instance (actual location is MacHD: private tmp local_qdrant)\n",
    "qdrant_path = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/qdrant\"\n",
    "# qdrant_path = \"/tmp/local_qdrant\"\n",
    "\n",
    "source_directory = \"./raw_pdfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea2a89",
   "metadata": {},
   "source": [
    "## 2. Chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDFs from directory...\n",
      "Processed AUXCA_SOP_005_B__20AUG24_ESIGN.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pypdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "def extract_metadata_from_pdfs(pdfs_source_dir):\n",
    "    file_list = []\n",
    "    pages = []\n",
    "    total_size = 0\n",
    "\n",
    "    # Check if the path is a directory or a file\n",
    "    if os.path.isdir(pdfs_source_dir):\n",
    "        print(\"Loading PDFs from directory...\")\n",
    "        for foldername, subfolders, filenames in os.walk(pdfs_source_dir):\n",
    "            for file in filenames:\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    process_pdf(os.path.join(foldername, file),\n",
    "                                file_list, pages, total_size)\n",
    "    elif os.path.isfile(pdfs_source_dir) and pdfs_source_dir.lower().endswith('.pdf'):\n",
    "        print(\"Loading a single PDF file...\")\n",
    "        process_pdf(pdfs_source_dir, file_list, pages, total_size)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Error: The path '{pdfs_source_dir}' is not a valid directory or PDF file!\")\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path, file_list, pages, total_size):\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        file_processed = False  # Flag to track if the file has been processed\n",
    "\n",
    "        for doc in documents:\n",
    "            with open(doc.metadata[\"source\"], \"rb\") as pdf_file_obj:\n",
    "                reader = pypdf.PdfReader(pdf_file_obj)\n",
    "                pdf_metadata = reader.metadata\n",
    "                doc.metadata.update(\n",
    "                    {key: pdf_metadata[key] for key in pdf_metadata.keys()})\n",
    "\n",
    "            pages.append(doc)\n",
    "            if not file_processed:\n",
    "                file_list.append(pdf_path.split('/')[-1])\n",
    "                total_size += os.path.getsize(pdf_path)\n",
    "                file_processed = True  # Set flag to True after processing the file\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "\n",
    "    if file_processed:\n",
    "        print(f\"Processed {pdf_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "pages = extract_metadata_from_pdfs(source_directory)\n",
    "if pages:\n",
    "    last_page = pages[-1]\n",
    "else:\n",
    "    print(\"No pages were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab05e49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='United States Coast Guard Auxiliary  \\n \\n \\n \\n \\n \\n \\n \\nAuxiliary Culinary Assistan ce (AUX CA) \\nProgram  \\n \\nStandard Operating Procedures', metadata={'source': './enriched_pdfs/AUXCA_SOP_005_B__20AUG24_ESIGN.pdf', 'page': 0, '/Producer': 'pypdf', '/title': 'AUXILIARY CULINARY ASSISTANCE (AUXCA) PROGRAM STANDARD OPERATING PROCEDURES', '/leadership_scope': '1_National', '/page_count': '30', '/creation_date': '2024-08-22T00:00:00Z', '/effective_date': '2024-11-02T17:17:07Z', '/upsert_date': '2024-11-02T17:17:07Z', '/expiration_date': '2034-11-03T05:17:07Z', '/lifecycle': 'none', '/aux_specific': 'True', '/public_release': 'True', '/publication_number': 'nan', '/source': 'cgaux.org', '/originator': 'CG-BSX-1', '/curator': 'Wilkins,CA', '/pdf_id': 'b69af3d6-96ee-5a1b-8a1e-9a6feca305b2', '/pdf_file_name': 'AUXCA_SOP_005_B__20AUG24_ESIGN'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# chunks at the page break\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config[\"chunk_size\"],\n",
    "    chunk_overlap=config[\"chunk_overlap\"],\n",
    "    length_function=config[\"length_function\"],\n",
    "    separators=config[\"separators\"]\n",
    ")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "# concat.pages_to_page(pages) #concatenates all the pages of the pdf into one\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "'''\"chunks\" is a list of objects of the class langchain.schema.document.Document'''\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3fd9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Source folder: ./enriched_pdfs\n",
      "        Pages processed: 30\n",
      "        Text splitter: CharacterTextSplitter\n",
      "        Chunk size: 2000 characters\n",
      "        Chunk overlap: 200 characters\n",
      "        Chunks (vectors) created: 30 \n",
      "        Dictionary size: 0.48 MB\n",
      "        Vectorstore tokens: 24627\n",
      "        Estimated memory size (Qdrant): 0.26 MB\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def print_document_load_summary(source_directory):\n",
    "    from pympler import asizeof\n",
    "    import tiktoken\n",
    "\n",
    "    encoding = tiktoken.encoding_for_model(config[\"model\"])\n",
    "    vectorstore_tokens = encoding.encode(str(chunks))\n",
    "    num_vectorestore_tokens = len(vectorstore_tokens)\n",
    "    num_chunks = len(chunks)\n",
    "    # Qudrant's formula is memory_size in bytes = number_of_vectors * vector_dimension * 4 bytes * 1.5\n",
    "    memory_size = num_chunks * config[\"embedding_dims\"] * 4 * 1.5\n",
    "\n",
    "    print(f\"\"\"\n",
    "        Source folder: {source_directory}\n",
    "        Pages processed: {len(pages)}\n",
    "        Text splitter: {config[\"splitter_type\"]}\n",
    "        Chunk size: {config[\"chunk_size\"]} characters\n",
    "        Chunk overlap: {config[\"chunk_overlap\"]} characters\n",
    "        Chunks (vectors) created: {num_chunks} \n",
    "        Dictionary size: {asizeof.asizeof(pages) / (1024 * 1024):.2f} MB\n",
    "        Vectorstore tokens: {num_vectorestore_tokens}\n",
    "        Estimated memory size (Qdrant): {memory_size / (1024 * 1024):.2f} MB\n",
    "    \"\"\")\n",
    "\n",
    "    ''' TODO These variables are now in a function so not accessible.    \n",
    "        Document(s)loaded: {len(file_list)}\n",
    "        Load size: {total_size / (1024 * 1024):.2f} MB\n",
    "        '''\n",
    "\n",
    "\n",
    "print_document_load_summary(source_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1d5c5",
   "metadata": {},
   "source": [
    "## 4. Add chunks to Qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.qdrant.Qdrant at 0x16661cd50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a langchain vectorstore object\n",
    "# langchain.vectorstores.Qdrant was deprecated since 0.1.2. Works here but legacy\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "qdrant = Qdrant(client=client,\n",
    "                collection_name=qdrant_collection_name,\n",
    "                # embedding here is LC interface to the embedding model\n",
    "                embeddings=config[\"embedding\"],\n",
    "                )\n",
    "\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d3a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.qdrant.Qdrant at 0x14354cfd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .from_documents  creates the Qdrant vectorstore object with the documents/chunks, embeddings, and metadata and automatically configures the collection.  It is a Langchain class method used to initialize a new Qdrant instance with a collection of documents all at once.\n",
    "\n",
    "qdrant.from_documents(\n",
    "    chunks,\n",
    "    embedding=config[\"embedding\"],  # yes this is required here too\n",
    "    # path=qdrant_path,  # Only required for local instance\n",
    "    collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "    url=st.secrets[\"QDRANT_URL\"],\n",
    "    api_key=st.secrets[\"QDRANT_API_KEY\"],  # Only required for Qdrant Cloud\n",
    "    # keep this to falsse so you don[t overwrite your collection\n",
    "    force_recreate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9d64f",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"><b>CONGRATULATIONS: You're done</b></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937261bc",
   "metadata": {},
   "source": [
    "## OPTIONAL: Create NEW vector store and add documents into it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8c8db",
   "metadata": {},
   "source": [
    "#### Combo Create + Add Docs\n",
    "\n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing Qdrant collection</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "\n",
    "def create_localdb_and_add_chunks():\n",
    "    \"\"\"Use only to create the vectore db and load docs the first time. \n",
    "\n",
    "    .from_documents  creates the Qdrant vectorstore object with the documents/chunks, embeddings, and metadata and automatically configures the collection.  It is a Langchain class method used to initialize a new Qdrant instance with a collection of documents all at once.\n",
    "\n",
    "    It overcomes limitations in Langchain by releaseing the vecDB afterwards\"\"\"\n",
    "\n",
    "    client = QdrantClient()\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=qdrant_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "    qdrant.from_documents(\n",
    "        chunks,\n",
    "        embedding=config[\"embedding\"],  # yes this is required here too\n",
    "        path=qdrant_path,  # Only required for local instance\n",
    "        collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "        # url=os.environ.get(\"QDRANT_URL\"),\n",
    "        # Only required for Qdrant Cloud\n",
    "        # api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    "        force_recreate=False,  # don't use if db doesn't already exist\n",
    "    )\n",
    "    # print(client.get_collections())\n",
    "    # print(\n",
    "    # f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")\n",
    "\n",
    "\n",
    "check_me = create_localdb_and_add_chunks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed726a9b",
   "metadata": {},
   "source": [
    "#### Create new Qdrant DB / Collection.\n",
    "\n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing Qdrant collection</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may not work\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "client = QdrantClient(\n",
    "    path=qdrant_path\n",
    ")  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=new_collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=config[\"embedding_dims\"], distance=models.Distance.COSINE)\n",
    ")\n",
    "# You may need to delete the lock file to access this afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24657b",
   "metadata": {},
   "source": [
    "#### Add Documents with Timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def add_chunks_to_existingdb_with_delay(batch_size, delay):\n",
    "    \"\"\"\n",
    "    Use only to create the vectore db and load docs the first time. (7min)\n",
    "    This version loads the chunks into the vector store with a delay.\n",
    "\n",
    "    Unlike .from_documents, which is a class method of Qdrant, \n",
    "    this uses  .add_documents which is an instance method of DocArrayInMemorySearch.\n",
    "    This means you have to set up th Qdrant instance first before using it. \n",
    "    By separating the two we can insert a timer delay. It releases the vecDB afterwards.\n",
    "\n",
    "    USAGE: Aim for ~800K tokens and then have the timer delay until 60 sec is reached\n",
    "    \"\"\"\n",
    "\n",
    "    from qdrant_client import QdrantClient\n",
    "    from langchain.vectorstores import Qdrant\n",
    "\n",
    "    client = QdrantClient(\n",
    "        path=qdrant_path\n",
    "    )  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=new_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "\n",
    "    # generate indices starting from 0. increment by batch_size until len(chunks)\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]  # Create a batch of chunks\n",
    "        qdrant.add_documents(documents=batch)  # Add the batch of chunks\n",
    "        # pause time probably don't need to be changed since tokens usually hit limit by 18 sec.\n",
    "        time.sleep(delay)\n",
    "\n",
    "    del qdrant\n",
    "    client.close()    # Release the database from this process\n",
    "    del client\n",
    "\n",
    "\n",
    "add_chunks_to_existingdb_with_delay(1700, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f26af",
   "metadata": {},
   "source": [
    "## OPTIONAL: Close Client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
