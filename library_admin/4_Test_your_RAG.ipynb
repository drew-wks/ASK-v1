{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-v1/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Confirm you're using the correct interpreter\n",
    "#\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip list # See what's installed and versions\n",
    "# %pip install openai==0.27.8\n",
    "# %pip install langchain==0.0.315\n",
    "# %pip install --upgrade docarray\n",
    "# %pip install python-doten\n",
    "# %pip install --upgrade wandb\n",
    "# %pip install qdrant-client==1.6.3\n",
    "# %pip install pympler==1.1.3\n",
    "# %pip install pypdf==5.0.1\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# required for langchain.embeddings.OpenAIEmbeddings. If this form of the key doesn't work, try OPENAI_API_KEY = st.secrets[\"QDRANT_API_KEY\"]\n",
    "\n",
    "openai.api_key = st.secrets[\"QDRANT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"search_type\": \"mmr\",\n",
    "    'fetch_k': 20,   # number of documents to pass to the search alg (eg., mmr)\n",
    "    \"k\": 5,  # number of document from fetch to pass to the LLM for inference\n",
    "    'lambda_mult': .7,    # 0= max diversity, 1 is max relevance. default is 0.5\n",
    "    \"score_threshold\": 0.5,  # for similarity score\n",
    "    \"model\": \"gpt-3.5-turbo-16k_\",  # gpt-4, gpt-3.5-turbo-16k\n",
    "    \"temperature\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_collection_name = \"ASK_vectorstore\"\n",
    "# Only required for local instance (actual location is MacHD: private tmp local_qdrant)\n",
    "qdrant_path = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/qdrant\"\n",
    "# qdrant_path = \"/tmp/local_qdrant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Vector Store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a Qdrant service entrypoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='ask_pdf_pages'), CollectionDescription(name='ASK_vectorstore'), CollectionDescription(name='ask_pdf_docs')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "'''\n",
    "If you receive an error that the client is already open, first use these commands to close it nd then run the code again\n",
    "\n",
    "del qdrant\n",
    "client.close()    # Release the database from this process\n",
    "del client\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "if 'client' not in globals():\n",
    "    client = QdrantClient(url=st.secrets[\"QDRANT_URL\"],\n",
    "                          api_key=st.secrets[\"QDRANT_API_KEY\"])\n",
    "else:\n",
    "    print(f\"Client already exists at {client}\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm client is initialized and location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client is running via a URL.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.local.qdrant_local import QdrantLocal\n",
    "from qdrant_client.qdrant_remote import QdrantRemote\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check if the client is running locally or via a URL\n",
    "    if isinstance(client._client, QdrantLocal):\n",
    "        print(\"The client is running locally.\")\n",
    "    elif isinstance(client._client, QdrantRemote):\n",
    "        print(\"The client is running via a URL.\")\n",
    "    else:\n",
    "        # This else block handles cases where client._client is neither QdrantLocal nor QdrantRemote\n",
    "        print(\"Unable to determine the running mode of the Qdrant client.\")\n",
    "except Exception as e:\n",
    "    # This block catches any other exceptions that might occur\n",
    "    print(\"Unable to determine the running mode of the Qdrant client. Error: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "\n",
    "qdrant = Qdrant(\n",
    "client=client,\n",
    "collection_name=qdrant_collection_name, # embedding here is a LC interface to the embedding model,\n",
    "embeddings=config[\"embedding\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "\n",
    "qdrant = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=qdrant_collection_name,\n",
    "    # embedding here is a LC interface to the embedding model,\n",
    "    embeddings=config[\"embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a VectorStoreRetriever called retriever from the LC qdrant vector store object\n",
    "\n",
    "# Option 1 using MMR search\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': config[\"k\"], \"fetch_k\": config[\"fetch_k\"],\n",
    "                   \"lambda_mult\": config[\"lambda_mult\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize a Document Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import re\n",
    "\n",
    "\n",
    "# Regular expression pattern to match metadata inside parentheses\n",
    "metadata_pattern = re.compile(r\"metadata=\\{(.*?)\\}\")\n",
    "\n",
    "# Function to extract metadata\n",
    "\n",
    "\n",
    "def extract_metadata(doc_list):\n",
    "    metadata_list = []\n",
    "    for doc in doc_list:\n",
    "        # Convert doc to string if it's not already a string\n",
    "        if not isinstance(doc, str):\n",
    "            doc = str(doc)\n",
    "\n",
    "        matches = metadata_pattern.findall(doc)\n",
    "        for match in matches:\n",
    "            # Convert the matched string to a dictionary\n",
    "            metadata_dict = eval('{' + match + '}')\n",
    "            metadata_list.append(metadata_dict)\n",
    "    return metadata_list\n",
    "\n",
    "\n",
    "# Print each metadata dictionary as a Markdown list item\n",
    "def display_selected_metadata_as_markdown(metadata_list):\n",
    "    # Start with an empty string\n",
    "    markdown_string = \"\"\n",
    "\n",
    "    # Iterate over each metadata dictionary\n",
    "    for metadata in metadata_list:\n",
    "        # Extract the /Title and page values\n",
    "        source = metadata.get('source', 'No Source')\n",
    "        page = metadata.get('page', 'No Page')\n",
    "\n",
    "        # Add them as a list item in the markdown string\n",
    "        markdown_string += \"Source: {}, Page: {}  \\n\".format(\n",
    "            source, page)\n",
    "    return markdown_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run a Query and Check the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Source: ./raw_pdfs/BSX Policy Letter_AUX-PL-001-B_19-01_UPDATED RISK MANAGEMENT TRAINING REQUIREMENTS FOR THE COAST GUARD AUXILIARY.pdf, Page: 3  \n",
       "Source: References/Gold Side/Flotilla_Procedures_Guide_FINAL_ESIGNED_23MAR23.pdf, Page: 0  \n",
       "Source: For_injestion/2023 Surface Operations_Workshop Rev1.8.pptx.pdf, Page: 29  \n",
       "Source: For_injestion/2023 Telecomms_TCO_Workshop Rev 1.4.pptx.pdf, Page: 8  \n",
       "Source: References/Auxiliary Manual CIM_16790_1G.pdf, Page: 362  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"AUX-PL-001(A) RISK MANAGEMENT TRAINING REQUIREMENTS FOR THE COAST GUARD AUXILIARY\")\n",
    "\n",
    "# Extracting metadata\n",
    "metadata_list = extract_metadata(retrieved_docs)\n",
    "\n",
    "# Assuming metadata_list is your list of metadata dictionaries\n",
    "markdown_string = display_selected_metadata_as_markdown(metadata_list)\n",
    "\n",
    "# Display the markdown string\n",
    "display(Markdown(markdown_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
